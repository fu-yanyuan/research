CLIP (Contrastive Languageâ€“Image Pre-training) 
---
Paper: [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)  
Blog: [CLIP: Connecting Text and Images](https://openai.com/blog/clip/#rf13)  
Bilibili: [limu](https://www.bilibili.com/video/BV1SL4y1s7LQ/?spm_id_from=333.788)

It seems that CLIP is good at abstaction, which may contribute to sketchy.   
Also, there are some amazing results that combine CLIP with NeRF.  
Anyway, let's have a look at it.  

---------------------

